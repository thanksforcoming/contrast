---
title:  "Welcome to Diversity"
layout: post
---

Today, I will be a little out of the circle of social media. I will be writing to you about diversity. 
Of course, you can always think about the diversity on social media, but I want to first write about the news and maybe later 
I will dig in the diversity in social media.

The diversity subject came to me because of 
[Standing with Dr. Timnit Gebru](https://googlewalkout.medium.com/standing-with-dr-timnit-gebru-isupporttimnit-believeblackwomen-6dadc300d382). 
Dr. Timnit Gebru is a computer scientist who works on algorithmic bias. She was fired by Google by an email, 
because of her research about the company's doing. Google first said that she resigned, 
but she refused and explained that Google fired her.  Why is this case important?

Think about a woman who wants to be an engineer, a computer engineer. 
Then think that she is a woman of color from Ethiopia. She is a part of a group that is one percent of the employees in 
[Google](https://www.wired.com/story/five-years-tech-diversity-reports-little-progress/). 
There seems to be a misunderstanding about who fired whom, but it is not my concern for a moment. 
There are [tweets](https://twitter.com/timnitGebru/status/1334341991795142667) and 
[emails](https://www.platformer.news/p/the-withering-email-that-got-an-ethical) to check and understand the situation. 
As far as I understood, the reason for this leave is a research paper that has been declined by the researchers. 
As Jeff Dean wrote in an [email]((https://www.reddit.com/r/MachineLearning/comments/k6467v/n_the_email_that_got_ethical_ai_researcher_timnit/)): __it didn’t meet our bar for publication__. 

## The paper : On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?

What is this paper about? The paper is not officially published yet, but you can find it online (try reddit).
The paper is about the language models. As you know there are big models: BERT, GPT-2, GPT-3 etc. Using these language models improve 
the performance of the tasks in natural language processing. 
These recent models are examined in terms of their environment and financial cost in the paper. 
Did you know that the energy requirement to run a SOTA Bert-base model was estimated as much as a trans-American flight? 
This is a really important environmental result. There are several studies to show green AI, eco-friendly hardwares etc, 
but the main industry always shows us how Siri can speak fluently in English, __when the effect of climate change continues to set new records.__ 
Of course, these are also important developments, but the problem comes when thinking about the percentage of the population 
who can or cannot use these technologies.

Apart from the environmental effects, there are social effects of these language models. 
These huge language models learn from the real world. If the data is biased, then the generated language is also. 
The automated procedure can favor hate speech, racism and toxic conversations. 
Also, these models can generate human-quality fake news, how are we going to distinguish them from the real ones?
Of course, we can always develop detection methods using language models :/.

I didn't read the paper in detail, but overall I didn't face anything that can affect Google's doing and causes it to fire an employee, 
maybe I am too naive. Next week, I will try to examine the paper and support the facts if necessary.
